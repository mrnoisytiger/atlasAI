# Atlas AI

## Basics

This is the GitHub Repository for Project Atlas AI, the smarthome assistant for the UCLA Solar Decathlon 2019 House. The AI is designed to run in WebKit-supported browsers, namely Google Chrome 45+. Project Atlas is listening through the specified microphone for a "trigger phrase," using Google's Speech Recognition API. When the "trigger phrase" is heard, Atlas listens for a short time for a "command." Anything heard during that period of time will be considered part of the command. 

When the period of time listening for the command ends, the string of the command is sent to API.AI for natural language processing, which returns an "intent" and any related information, such as "entities" and "actions." Atlas then selects a connector to the back-end server, depending on the "intent" generated by API.AI. Each connector has it's own means of processing data, though the most basic involves sending the JSON-Object from API.AI directly to the backend, or calling a small "function" on Atlas directly. 

The API of Atlas is a POST-only endpoint. The API will accept JSON-Objects produced by API.AI and extract the intent of the object, similar to the client-side. The API will then, based off the extracted intent, call "API Extensions." These API Extensions execute the required action, based off the JSON-Object. 

The API Extensions often communicate with third-party API's which require authentication. This alone require the extensions to remain on the back-end. Also included in API Extensions are "Language Structures" or natural language responses to certain stimulus, specific to each Extension. 

## Why This is Open-Source

This project has finally been made open-source because I'm tired of managing my own development server. 
